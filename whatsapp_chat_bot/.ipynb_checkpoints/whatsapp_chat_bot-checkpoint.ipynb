{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatsapp chat bot\n",
    "\n",
    "## Summary\n",
    "\n",
    "WhatsApp allows you to download the message history of any conversation. In this project, I have built a model that can take any WhatsApp message history and turn it into a chat bot. As the chat bot is based on the messages of the friend the user has been messaging, the chat bot's personality is based on that of your friend.\n",
    "\n",
    "The user uploads a WhatsApp message history, and the chat bot learns from this dataset. The user then inputs a message, and the model finds a message sent by the user in the dataset which is most similar to the input message. The model then selects the response corresponding to this most similar message from the dataset. The response is then given by the chat bot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "First, the model loads and processes the conversation history, which has been downloaded by the user directly from WhatsApp as a .txt file. Conversations tend to have groups of messages from each person before the other person responds. As a simplification, the model extracts the last message of a group sent by the user, and the first message received in response to this. This gives a pair of messages: a message sent by the user and a response from the user's friend. So at this stage the model has an array of messages and an array of corresponding responses.\n",
    "\n",
    "In processing the data, the model has an option to remove stop words. Stop words are typically removed from data used for Natural Language Processing because they are very common and have little specialised meaning. However, I have found that removing stop words in the chat bot worsens the results. This is likely to be because small talk contains a lot of stop words. For example, 'how', 'are', and 'you' are all stop words. By default, the chat bot therefore does not remove stop words.\n",
    "\n",
    "The chat bot also makes all of the chat data lower case, and by doing so assumes there is no important distinction between upper and lower case letters in the WhatsApp conversation.\n",
    "\n",
    "Once the chat history has been converted into a list of messages from the user and responses to the user. The messages from the user are tagged and used to train a doc2vec model which uses DM-PV (Distributed Memory version of Paragraph Vector) to convert each message into a numerical vector, where each vector corresponds to a position in 'meaning space'.\n",
    "\n",
    "After the chat bot has been trained on the input message history, it can have a conversation with the user. The user must input a message, and the chat bot then takes that message and converts it into a vector. The chat bot then finds the vector in the meaning space which closest to the new message vector. In other words, it finds the message that has the closest meaning to the new message. The chat bot then simply returns the response from the user's friend that corresponds to the closest message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat bot class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    \n",
    "    def __init__(self, my_name, friend_name, chat_file_path, remove_stop_words=False):\n",
    "        '''\n",
    "        Initialise the chat bot, and load and process the data.\n",
    "        '''\n",
    "        \n",
    "        # The name of the person who has downloaded the chat data\n",
    "        self.my_name = my_name\n",
    "        # The name of the other person\n",
    "        self.friend_name = friend_name\n",
    "        # Option to remove stop words from the data\n",
    "        self.remove_stop_words = remove_stop_words\n",
    "        \n",
    "        # Load the raw chat data\n",
    "        chat = open(chat_file_path)\n",
    "        chat_text = chat.read()\n",
    "        raw_chat = chat_text.splitlines()\n",
    "        \n",
    "        # List of messages from me\n",
    "        self.me_chat = []\n",
    "        # Corresponding list of responses to my messages\n",
    "        self.friend_chat = []\n",
    "        \n",
    "        # The first element denotes the name of the sender and the second denotes the message sent\n",
    "        previous_row = [None, None]\n",
    "\n",
    "        # Iterate through all messages\n",
    "        n = len(raw_chat)\n",
    "        for i in range(n):\n",
    "            row = raw_chat[i]\n",
    "            # Check that the row is not empty\n",
    "            if len(row) != 0:\n",
    "                # Check that the row is valid, i.e. excludes picture messages, etc.\n",
    "                # Valid rows start with a '['\n",
    "                if row[0] == '[':\n",
    "                    # Remove time stamp in row\n",
    "                    row = row.split('] ')[1]\n",
    "                    # Split the remaining string into the name of the sender, and the message\n",
    "                    row = row.split(': ')[0:2]\n",
    "                    # Only keep the last message in a string of messages from me, and my friend's first response to this\n",
    "                    if previous_row[0] == my_name and row[0] != my_name:\n",
    "                        self.me_chat.append(previous_row[1])\n",
    "                        self.friend_chat.append(row[1])\n",
    "                    previous_row = row\n",
    "        \n",
    "        # Option to remove stop words\n",
    "        if self.remove_stop_words == True:\n",
    "            stop_words = stopwords.words('english')\n",
    "        \n",
    "        # The tagged message data\n",
    "        self.tagged_data = []\n",
    "        \n",
    "        # Create tagged documents for each message from me\n",
    "        n = len(self.me_chat)\n",
    "        for i in range(n):\n",
    "            message = word_tokenize(self.me_chat[i].lower())\n",
    "            if self.remove_stop_words == True:\n",
    "                tagged_message = [word for word in message if word not in stop_words]\n",
    "            else:\n",
    "                tagged_message = message\n",
    "            self.tagged_data.append(TaggedDocument(words=tagged_message, tags = [i]))\n",
    "\n",
    "    def train(self, max_epochs=100, vec_size=100, alpha=0.025):\n",
    "        \n",
    "        # Instantiate the Doc2Vec model\n",
    "        self.model = Doc2Vec(vector_size=vec_size,\n",
    "                             alpha=alpha, \n",
    "                             min_alpha=0.00025,\n",
    "                             min_count=1,\n",
    "                             dm =1)\n",
    "        \n",
    "        # Build the vocab using the tagged data\n",
    "        self.model.build_vocab(self.tagged_data)\n",
    "        \n",
    "        # Iterate through each training epoch\n",
    "        for epoch in range(max_epochs):\n",
    "            # Output a message to indicate progress\n",
    "            if epoch % 10 == 0:\n",
    "                print('Iteration: ' +  str(epoch) + ' / ' + str(max_epochs))\n",
    "            # Train the model\n",
    "            self.model.train(self.tagged_data,\n",
    "                             total_examples=self.model.corpus_count,\n",
    "                             epochs=self.model.epochs)\n",
    "            # Decrease the learning rate\n",
    "            self.model.alpha -= 0.0002\n",
    "            # Fix the learning rate, no decay\n",
    "            self.model.min_alpha = self.model.alpha\n",
    "        \n",
    "        model_file_name = self.friend_name + \"_doc2vec.model\"\n",
    "        self.model.save(model_file_name)\n",
    "        self.model = Doc2Vec.load(model_file_name)\n",
    "        self.model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "        print('Iteration: ' +  str(max_epochs) + ' / ' + str(max_epochs))\n",
    "        print(\"Model Saved\")\n",
    "        \n",
    "    def message(self, message):\n",
    "        \n",
    "        # Make the message lower case and tokenize it\n",
    "        message = word_tokenize(message.lower())\n",
    "        \n",
    "        # Option to remove stop words\n",
    "        if self.remove_stop_words == True:\n",
    "            message = [word for word in message if word not in stop_words]\n",
    "            \n",
    "        # Infer the message's vector\n",
    "        message_vector = self.model.infer_vector(message, epochs=1000)\n",
    "        \n",
    "        # Find the most similar message to the message given\n",
    "        similar_message = self.model.docvecs.most_similar([message_vector])[0][0]\n",
    "        print(self.friend_name + ': ' + self.friend_chat[similar_message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alison_chat_bot = ChatBot(my_name='Guy', friend_name='Alison',\n",
    "                   chat_file_path='/Users/guybrett-robertson/Documents/data/whatsapp_chats/alison_chat.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 / 100\n",
      "Iteration: 10 / 100\n",
      "Iteration: 20 / 100\n",
      "Iteration: 30 / 100\n",
      "Iteration: 40 / 100\n",
      "Iteration: 50 / 100\n",
      "Iteration: 60 / 100\n",
      "Iteration: 70 / 100\n",
      "Iteration: 80 / 100\n",
      "Iteration: 90 / 100\n",
      "Iteration: 100 / 100\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "alison_chat_bot.train(max_epochs=100, vec_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input messages that are the same as messages present in the chat data set\n",
    "\n",
    "We would expect the chat bot to give the same response as the original response that was given in the chat data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me: Gnight Alison x\n",
      "Alison: Have a good night ‚ò∫Ô∏è x\n"
     ]
    }
   ],
   "source": [
    "print('Me: ' + alison_chat_bot.me_chat[213])\n",
    "print('Alison: ' + alison_chat_bot.friend_chat[213])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alison: Have a good night ‚ò∫Ô∏è x\n"
     ]
    }
   ],
   "source": [
    "alison_chat_bot.message('Gnight Alison x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me: I just totally forgot ‚Äî where is your place a Londres?\n",
      "Alison: Kilburn :)\n"
     ]
    }
   ],
   "source": [
    "print('Me: ' + alison_chat_bot.me_chat[294])\n",
    "print('Alison: ' + alison_chat_bot.friend_chat[294])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alison: Kilburn :)\n"
     ]
    }
   ],
   "source": [
    "alison_chat_bot.message('I just totally forgot ‚Äî where is your place a Londres?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages that are similar but not identical to messages present in the chat data set\n",
    "\n",
    "We would expect the chat bot to give some reasonable responses to these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alison: √áa va merci :) quoi de neuf aujourd'hui ?\n"
     ]
    }
   ],
   "source": [
    "alison_chat_bot.message('Ca va?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alison: Amazing üòÑü•∞\n"
     ]
    }
   ],
   "source": [
    "alison_chat_bot.message('Yayyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alison: Bonjour toi! :)\n"
     ]
    }
   ],
   "source": [
    "alison_chat_bot.message(\"How's it going?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alison: I miss you too x\n"
     ]
    }
   ],
   "source": [
    "alison_chat_bot.message(\"I miss you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completely new messages\n",
    "\n",
    "We wouldn't expect the chat bot to give particularly reasonable responses to these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alison: Ah right! Hope it goes well :) did you know her already?\n"
     ]
    }
   ],
   "source": [
    "alison_chat_bot.message('What is the meaning of life?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alison: Yes üòÑ\n"
     ]
    }
   ],
   "source": [
    "alison_chat_bot.message('The quick brown fox jumps over the lazy dog.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alison: Basically I had left her gift (the frame) in my car so we would take it when she leaves to get the pizzas. Except she locked us inside, the door and the gate were closed üòÜ so I had to climb out the window and stuff and then climb back in ü§£\n"
     ]
    }
   ],
   "source": [
    "alison_chat_bot.message('What are you going to do yesterday?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
